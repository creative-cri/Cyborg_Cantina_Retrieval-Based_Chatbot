{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "607a9d8d",
   "metadata": {},
   "source": [
    "# Cyborg Cantina Retrieval-Based Chatbot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3edeed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_a = \"The {} has a gluten-free option, but it is not vegan\"\n",
    "response_b = \"We have a selection of sides to go along with the {}, including mashed potatoes and steamed vegatables.\"\n",
    "response_c = \"{} includes habanero, so it is a bit spicy!\"\n",
    "blank_spot = \"food\"\n",
    "\n",
    "\n",
    "responses = [response_a, response_b, response_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e6a5ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "import spacy\n",
    "word2vec = spacy.load('en_core_web_sm')\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess(input_sentence):\n",
    "    input_sentence = input_sentence.lower()\n",
    "    input_sentence = re.sub(r'[^\\w\\s]','',input_sentence)\n",
    "    tokens = word_tokenize(input_sentence)\n",
    "    input_sentence = [i for i in tokens if not i in stop_words]\n",
    "    return(input_sentence)\n",
    "\n",
    "def compare_overlap(user_message, possible_response):\n",
    "    similar_words = 0\n",
    "    for token in user_message:\n",
    "        if token in possible_response:\n",
    "              similar_words += 1\n",
    "    return similar_words\n",
    "  \n",
    "def extract_nouns(tagged_message):\n",
    "    message_nouns = list()\n",
    "    for token in tagged_message:\n",
    "        if token[1].startswith(\"N\"):\n",
    "            message_nouns.append(token[0])\n",
    "    return message_nouns\n",
    "\n",
    "def compute_similarity(tokens, category):\n",
    "    output_list = list()\n",
    "    for token in tokens:\n",
    "        output_list.append([token.text, category.text, token.similarity(category)])\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eafec21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! What would you like to know about our menu today? what do you have ?\n",
      "The food has a gluten-free option, but it is not vegan\n",
      "Do you have any other questions? no\n",
      "Ok, bye!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import spacy\n",
    "word2vec = spacy.load('en_core_web_sm')\n",
    "\n",
    "exit_commands = (\"quit\", \"goodbye\", \"exit\", \"no\")\n",
    "\n",
    "class ChatBot:  \n",
    "  #define .make_exit() below:\n",
    "  def make_exit(self, user_message):\n",
    "    for exit_command in exit_commands:\n",
    "      if exit_command in user_message:\n",
    "        print(\"Ok, bye!\")\n",
    "        return True \n",
    "      \n",
    "  #define .chat() below:\n",
    "  def chat(self):\n",
    "    user_message = input(\"Hey! What would you like to know about our menu today? \")\n",
    "    while not self.make_exit(user_message):\n",
    "      user_message = self.respond(user_message)\n",
    "\n",
    "  #define .find_intent_match() below:\n",
    "  def find_intent_match(self, responses, user_message):\n",
    "    bow_user_message = Counter(preprocess(user_message))\n",
    "    processed_responses = [Counter(preprocess(response)) for response in responses]\n",
    "    similarity_list = [compare_overlap(doc, bow_user_message) for doc in processed_responses]\n",
    "    response_index = similarity_list.index(max(similarity_list))\n",
    "    return responses[response_index]\n",
    "\n",
    "  #define .find_entities() below:\n",
    "  def find_entities(self, user_message):\n",
    "    tagged_user_message = pos_tag(preprocess(user_message))\n",
    "    message_nouns = extract_nouns(tagged_user_message)\n",
    "    tokens = word2vec(\" \".join(message_nouns))\n",
    "    category = word2vec(blank_spot)\n",
    "    word2vec_result = compute_similarity(tokens, category)\n",
    "    word2vec_result.sort(key=lambda x: x[2])\n",
    "    if len(word2vec_result) < 1:\n",
    "      return blank_spot\n",
    "    else:\n",
    "      return word2vec_result[-1][0]\n",
    "\n",
    "  #define .respond() below:\n",
    "  def respond(self, user_message):\n",
    "    best_response = self.find_intent_match(responses, user_message)\n",
    "    entity = self.find_entities(user_message)\n",
    "    print(best_response.format(entity))\n",
    "    input_message = input(\"Do you have any other questions? \")\n",
    "    return input_message\n",
    "\n",
    "#initialize ChatBot instance below:\n",
    "cantina_bot = ChatBot()\n",
    "#call .chat() method below:\n",
    "cantina_bot.chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9583168e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
